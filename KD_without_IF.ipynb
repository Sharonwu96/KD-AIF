{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad10a5-97ed-4b6c-804a-723e9dcc05d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.models.resnet import resnet34\n",
    "from torchvision.transforms.transforms import Resize\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize(224),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "#采用自带的Cifar100\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data_CIFAR100', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR100(root='./data_CIFAR100', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55992080-b267-4604-a4ca-dca019f87c4b",
   "metadata": {},
   "source": [
    "### 在数据集中加入weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334efbc1-5600-4327-9acf-b74b08a87b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "class CIFAR100(datasets.CIFAR100):\n",
    "    def __init__(self, root, indexs, influence_weight, train=True,\n",
    "                 transform=torchvision.transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]),\n",
    "                 download=True):\n",
    "        super().__init__(root, train=train,\n",
    "                         transform=transform,\n",
    "                         download=download)\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "            self.index = indexs\n",
    "            self.weight = influence_weight[indexs]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, targets,indexs,weight = self.data[index], \\\n",
    "                                    self.targets[index], \\\n",
    "                                    self.index[index],\\\n",
    "                                    self.weight[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, targets,indexs,weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4934b9e-e3e9-49d9-a8b1-b9d5279bc49c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "all_idx = np.array(range(len(trainset.targets)))\n",
    "default_weight = np.ones(len(trainset.targets))\n",
    "\n",
    "train_dataset = CIFAR100(root='./data_CIFAR100',\n",
    "     indexs = all_idx,influence_weight=default_weight, train=True\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc10575-ebaa-408a-a4bc-b335854f0a00",
   "metadata": {},
   "source": [
    "### 训练 Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8abbf2f-b0be-4628-b7a3-82f2c8ec91d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_model=models.resnet50(pretrained=True)\n",
    "    \n",
    "fc_inputs = teacher_model.fc.in_features #获得fc特征层的输入\n",
    "teacher_model.fc = nn.Sequential(         #重新定义特征层，根据需要可以添加自己想要的Linear层\n",
    "    nn.Linear(fc_inputs, 100),  #多加几层都没关系 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60baab3-bfb4-4faf-a1d8-41870840c9de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    " # Training\n",
    "def train_withif(epoch,batch_size):\n",
    "    print('\\nTrain: Epoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets,indexes,weights) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        weights = weights.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(torch.squeeze(inputs, 1))\n",
    "        loss = torch.sum(criterion_train(outputs, targets)*weights)/batch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx%100 ==0:\n",
    "            print('epoch: %d' % epoch, '| Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    # wandb.log({\n",
    "    #     \"Train_Loss\": train_loss,\n",
    "    #     \"Train_Acc\": 100. * correct / total\n",
    "    # })\n",
    "    \n",
    "def test(epoch):\n",
    "    print('\\nTest: Epoch: %d' % epoch)\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(torch.squeeze(inputs, 1))\n",
    "            loss = criterion_test(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('epoch: %d'% epoch, 'Acc: %.3f%% (%d/%d)'\n",
    "        %  (100.*correct/total, correct, total))\n",
    "    # wandb.log({\n",
    "    #     \"Test_Acc\": 100. * correct / total\n",
    "    # })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc747fa7-3b69-4f61-a8f8-405336da5f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Epoch: 0\n",
      "epoch: 0 | Loss: 4.609 | Acc: 1.562% (1/64)\n",
      "epoch: 0 | Loss: 2.805 | Acc: 33.029% (2135/6464)\n",
      "epoch: 0 | Loss: 2.104 | Acc: 46.261% (5951/12864)\n",
      "epoch: 0 | Loss: 1.839 | Acc: 51.557% (9932/19264)\n",
      "epoch: 0 | Loss: 1.681 | Acc: 54.941% (14100/25664)\n",
      "epoch: 0 | Loss: 1.581 | Acc: 57.117% (18314/32064)\n",
      "epoch: 0 | Loss: 1.508 | Acc: 58.707% (22581/38464)\n",
      "epoch: 0 | Loss: 1.452 | Acc: 59.912% (26879/44864)\n",
      "\n",
      "Test: Epoch: 0\n",
      "epoch: 0 Acc: 67.130% (6713/10000)\n",
      "\n",
      "Train: Epoch: 1\n",
      "epoch: 1 | Loss: 0.991 | Acc: 68.750% (44/64)\n",
      "epoch: 1 | Loss: 0.954 | Acc: 71.674% (4633/6464)\n",
      "epoch: 1 | Loss: 0.887 | Acc: 73.212% (9418/12864)\n",
      "epoch: 1 | Loss: 0.855 | Acc: 73.967% (14249/19264)\n",
      "epoch: 1 | Loss: 0.829 | Acc: 74.719% (19176/25664)\n",
      "epoch: 1 | Loss: 0.810 | Acc: 75.299% (24144/32064)\n",
      "epoch: 1 | Loss: 0.796 | Acc: 75.764% (29142/38464)\n",
      "epoch: 1 | Loss: 0.787 | Acc: 76.052% (34120/44864)\n",
      "\n",
      "Test: Epoch: 1\n",
      "epoch: 1 Acc: 72.650% (7265/10000)\n",
      "\n",
      "Train: Epoch: 2\n",
      "epoch: 2 | Loss: 0.633 | Acc: 76.562% (49/64)\n",
      "epoch: 2 | Loss: 0.653 | Acc: 79.935% (5167/6464)\n",
      "epoch: 2 | Loss: 0.603 | Acc: 81.157% (10440/12864)\n",
      "epoch: 2 | Loss: 0.585 | Acc: 81.811% (15760/19264)\n",
      "epoch: 2 | Loss: 0.566 | Acc: 82.474% (21166/25664)\n",
      "epoch: 2 | Loss: 0.555 | Acc: 82.731% (26527/32064)\n",
      "epoch: 2 | Loss: 0.550 | Acc: 82.776% (31839/38464)\n",
      "epoch: 2 | Loss: 0.549 | Acc: 82.755% (37127/44864)\n",
      "\n",
      "Test: Epoch: 2\n",
      "epoch: 2 Acc: 74.290% (7429/10000)\n",
      "\n",
      "Train: Epoch: 3\n",
      "epoch: 3 | Loss: 0.585 | Acc: 81.250% (52/64)\n",
      "epoch: 3 | Loss: 0.462 | Acc: 85.705% (5540/6464)\n",
      "epoch: 3 | Loss: 0.427 | Acc: 86.451% (11121/12864)\n",
      "epoch: 3 | Loss: 0.415 | Acc: 86.643% (16691/19264)\n",
      "epoch: 3 | Loss: 0.403 | Acc: 86.982% (22323/25664)\n",
      "epoch: 3 | Loss: 0.397 | Acc: 87.235% (27971/32064)\n",
      "epoch: 3 | Loss: 0.391 | Acc: 87.388% (33613/38464)\n",
      "epoch: 3 | Loss: 0.391 | Acc: 87.348% (39188/44864)\n",
      "\n",
      "Test: Epoch: 3\n",
      "epoch: 3 Acc: 73.770% (7377/10000)\n",
      "\n",
      "Train: Epoch: 4\n",
      "epoch: 4 | Loss: 0.255 | Acc: 89.062% (57/64)\n",
      "epoch: 4 | Loss: 0.344 | Acc: 88.583% (5726/6464)\n",
      "epoch: 4 | Loss: 0.330 | Acc: 89.132% (11466/12864)\n",
      "epoch: 4 | Loss: 0.318 | Acc: 89.488% (17239/19264)\n",
      "epoch: 4 | Loss: 0.306 | Acc: 89.924% (23078/25664)\n",
      "epoch: 4 | Loss: 0.305 | Acc: 90.020% (28864/32064)\n",
      "epoch: 4 | Loss: 0.302 | Acc: 90.144% (34673/38464)\n",
      "epoch: 4 | Loss: 0.303 | Acc: 90.059% (40404/44864)\n",
      "\n",
      "Test: Epoch: 4\n",
      "epoch: 4 Acc: 74.370% (7437/10000)\n"
     ]
    }
   ],
   "source": [
    "net = teacher_model.to(device)\n",
    "criterion_train = nn.CrossEntropyLoss(reduction='none')\n",
    "criterion_test = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) #减小 lr\n",
    "\n",
    "epoches = 5 #for example\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    train_withif(epoch,batch_size=64)\n",
    "    test(epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a475553-aa55-406a-b70c-6cbec40165f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_save_path='./resnet50_cifar100_epoch5_withoutif.pkl'\n",
    "torch.save(net.state_dict(),teacher_save_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ad957-76c5-4453-80b7-c3e59c9de1d6",
   "metadata": {},
   "source": [
    "### 训练 Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717757d4-be48-4fa7-a924-8b4190b9ffe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TS_train_1_withif_2(epoch,teacher_model,student_model,trainloader,soft_loss,optimizer,batch_size):\n",
    "    print('\\nTrain: Epoch: %d' % epoch)\n",
    "    student_model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    temp = 7\n",
    "    alpha = 0.3\n",
    "    \n",
    "    for batch_idx, (inputs, targets,indexes,weights) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        weights = weights.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_preds = teacher_model(torch.squeeze(inputs, 1))\n",
    "\n",
    "        # 学生模型预测\n",
    "        student_preds = student_model(torch.squeeze(inputs, 1))\n",
    "\n",
    "        # 计算蒸馏后的预测结果及soft_loss\n",
    "        distillation_loss = soft_loss(\n",
    "            F.log_softmax(student_preds/temp, dim=1),#log_softmax\n",
    "            F.softmax(teacher_preds/temp, dim=1)\n",
    "        )\n",
    "        #loss = distillation_loss*weights\n",
    "        loss = torch.sum(torch.sum(distillation_loss,dim=1)*weights)/batch_size\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = student_preds.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx%200 ==0:\n",
    "            print(batch_idx+1,'/', len(trainloader),'epoch: %d' % epoch, '| Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # wandb.log({\n",
    "    #     \"Train_Loss\": train_loss,\n",
    "    #     \"Train_Acc\": 100. * correct / total\n",
    "    # })\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\nTest: Epoch: %d' % epoch)\n",
    "    global best_acc\n",
    "    student_model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = student_model(torch.squeeze(inputs, 1))\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    print('epoch: %d'% epoch, 'Acc: %.3f%% (%d/%d)'\n",
    "        %  (100.*correct/total, correct, total))\n",
    "    # wandb.log({\n",
    "    #     \"Test_Acc\": 100. * correct / total\n",
    "    # })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0cb0b1c-bca8-4ece-a7c2-b0387e037ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_model=models.resnet50(pretrained=True)\n",
    "    \n",
    "fc_inputs = teacher_model.fc.in_features #获得fc特征层的输入\n",
    "teacher_model.fc = nn.Sequential(         #重新定义特征层，根据需要可以添加自己想要的Linear层\n",
    "    nn.Linear(fc_inputs, 100),  #多加几层都没关系 \n",
    ")\n",
    "\n",
    "teacher_model.load_state_dict(torch.load(teacher_save_path)) \n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "student_model=models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "student_model.classifier = nn.Sequential( \n",
    "    #重新定义特征层，根据需要可以添加自己想要的Linear层\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=100),  #多加几层都没关系\n",
    "    #nn.LogSoftmax(dim=1)\n",
    ")\n",
    " \n",
    "student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1035fbe2-ddd5-4850-b8db-bbd2461fd5d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Epoch: 0\n",
      "1 / 782 epoch: 0 | Loss: 0.234 | Acc: 1.562% (1/64)\n",
      "201 / 782 epoch: 0 | Loss: 0.234 | Acc: 2.651% (341/12864)\n",
      "401 / 782 epoch: 0 | Loss: 0.221 | Acc: 4.095% (1051/25664)\n",
      "601 / 782 epoch: 0 | Loss: 0.208 | Acc: 5.363% (2063/38464)\n",
      "\n",
      "Test: Epoch: 0\n",
      "epoch: 0 Acc: 13.160% (1316/10000)\n",
      "\n",
      "Train: Epoch: 1\n",
      "1 / 782 epoch: 1 | Loss: 0.153 | Acc: 10.938% (7/64)\n",
      "201 / 782 epoch: 1 | Loss: 0.146 | Acc: 15.236% (1960/12864)\n",
      "401 / 782 epoch: 1 | Loss: 0.139 | Acc: 16.852% (4325/25664)\n",
      "601 / 782 epoch: 1 | Loss: 0.134 | Acc: 18.500% (7116/38464)\n",
      "\n",
      "Test: Epoch: 1\n",
      "epoch: 1 Acc: 26.680% (2668/10000)\n",
      "\n",
      "Train: Epoch: 2\n",
      "1 / 782 epoch: 2 | Loss: 0.110 | Acc: 23.438% (15/64)\n",
      "201 / 782 epoch: 2 | Loss: 0.107 | Acc: 27.806% (3577/12864)\n",
      "401 / 782 epoch: 2 | Loss: 0.104 | Acc: 28.538% (7324/25664)\n",
      "601 / 782 epoch: 2 | Loss: 0.101 | Acc: 29.529% (11358/38464)\n",
      "\n",
      "Test: Epoch: 2\n",
      "epoch: 2 Acc: 34.650% (3465/10000)\n",
      "\n",
      "Train: Epoch: 3\n",
      "1 / 782 epoch: 3 | Loss: 0.087 | Acc: 35.938% (23/64)\n",
      "201 / 782 epoch: 3 | Loss: 0.085 | Acc: 35.129% (4519/12864)\n",
      "401 / 782 epoch: 3 | Loss: 0.083 | Acc: 35.934% (9222/25664)\n",
      "601 / 782 epoch: 3 | Loss: 0.081 | Acc: 36.650% (14097/38464)\n",
      "\n",
      "Test: Epoch: 3\n",
      "epoch: 3 Acc: 41.030% (4103/10000)\n",
      "\n",
      "Train: Epoch: 4\n",
      "1 / 782 epoch: 4 | Loss: 0.069 | Acc: 39.062% (25/64)\n",
      "201 / 782 epoch: 4 | Loss: 0.071 | Acc: 41.527% (5342/12864)\n",
      "401 / 782 epoch: 4 | Loss: 0.070 | Acc: 41.973% (10772/25664)\n",
      "601 / 782 epoch: 4 | Loss: 0.069 | Acc: 42.728% (16435/38464)\n",
      "\n",
      "Test: Epoch: 4\n",
      "epoch: 4 Acc: 46.780% (4678/10000)\n",
      "\n",
      "Train: Epoch: 5\n",
      "1 / 782 epoch: 5 | Loss: 0.064 | Acc: 45.312% (29/64)\n",
      "201 / 782 epoch: 5 | Loss: 0.062 | Acc: 46.789% (6019/12864)\n",
      "401 / 782 epoch: 5 | Loss: 0.061 | Acc: 47.358% (12154/25664)\n",
      "601 / 782 epoch: 5 | Loss: 0.060 | Acc: 48.050% (18482/38464)\n",
      "\n",
      "Test: Epoch: 5\n",
      "epoch: 5 Acc: 51.370% (5137/10000)\n",
      "\n",
      "Train: Epoch: 6\n",
      "1 / 782 epoch: 6 | Loss: 0.055 | Acc: 50.000% (32/64)\n",
      "201 / 782 epoch: 6 | Loss: 0.055 | Acc: 51.687% (6649/12864)\n",
      "401 / 782 epoch: 6 | Loss: 0.054 | Acc: 51.804% (13295/25664)\n",
      "601 / 782 epoch: 6 | Loss: 0.054 | Acc: 52.397% (20154/38464)\n",
      "\n",
      "Test: Epoch: 6\n",
      "epoch: 6 Acc: 54.580% (5458/10000)\n",
      "\n",
      "Train: Epoch: 7\n",
      "1 / 782 epoch: 7 | Loss: 0.051 | Acc: 53.125% (34/64)\n",
      "201 / 782 epoch: 7 | Loss: 0.050 | Acc: 55.037% (7080/12864)\n",
      "401 / 782 epoch: 7 | Loss: 0.049 | Acc: 55.245% (14178/25664)\n",
      "601 / 782 epoch: 7 | Loss: 0.049 | Acc: 55.600% (21386/38464)\n",
      "\n",
      "Test: Epoch: 7\n",
      "epoch: 7 Acc: 57.250% (5725/10000)\n",
      "\n",
      "Train: Epoch: 8\n",
      "1 / 782 epoch: 8 | Loss: 0.049 | Acc: 64.062% (41/64)\n",
      "201 / 782 epoch: 8 | Loss: 0.045 | Acc: 57.711% (7424/12864)\n",
      "401 / 782 epoch: 8 | Loss: 0.045 | Acc: 57.906% (14861/25664)\n",
      "601 / 782 epoch: 8 | Loss: 0.045 | Acc: 58.270% (22413/38464)\n",
      "\n",
      "Test: Epoch: 8\n",
      "epoch: 8 Acc: 58.870% (5887/10000)\n",
      "\n",
      "Train: Epoch: 9\n",
      "1 / 782 epoch: 9 | Loss: 0.045 | Acc: 62.500% (40/64)\n",
      "201 / 782 epoch: 9 | Loss: 0.042 | Acc: 59.958% (7713/12864)\n",
      "401 / 782 epoch: 9 | Loss: 0.042 | Acc: 60.061% (15414/25664)\n",
      "601 / 782 epoch: 9 | Loss: 0.042 | Acc: 60.368% (23220/38464)\n",
      "\n",
      "Test: Epoch: 9\n",
      "epoch: 9 Acc: 60.560% (6056/10000)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "soft_loss = nn.KLDivLoss(reduction=\"none\")\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01,momentum=0.9)\n",
    "batch_size=64\n",
    "temp = 7\n",
    "\n",
    "epoches=10 #for example\n",
    "\n",
    "for epoch in range(epoches): \n",
    "    TS_train_1_withif_2(epoch,teacher_model,student_model,train_dataloader,soft_loss,optimizer,batch_size)\n",
    "    test(epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48b28c46-df3f-41ce-8ca6-e5a9dac0ed36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_save_path='./Dis_resnet50(T)_mobilebetv2(S)_cifar100_epoch10_withif_1.pkl'\n",
    "torch.save(student_model.state_dict(),student_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c2c94-27e2-4a5d-937e-fa32bcc9ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoches=50\n",
    "\n",
    "# for epoch in range(epoches): \n",
    "#     TS_train_1_withif_2(epoch,teacher_model,student_model,train_dataloader,soft_loss,optimizer,batch_size)\n",
    "#     test(epoch)\n",
    "#     if epoch==30:\n",
    "#         save_path='./save_model_202312/Dis_resnet50(T)_vgg(S)_cifar100_epoch30_withif_1.pkl'\n",
    "#         torch.save(student_model.state_dict(),save_path) \n",
    "\n",
    "# save_path='./save_model_202312/Dis_resnet50(T)_vgg(S)_cifar100_epoch50_withif_1.pkl'\n",
    "# torch.save(student_model.state_dict(),save_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e7acd-efef-4bbe-aab8-a69ecc763eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
